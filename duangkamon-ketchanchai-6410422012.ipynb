{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Ranking : 26 (Duangkamon Ket)\n\n#### 6410422012 Duangkamon Ketchanchai","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T13:21:11.462330Z","iopub.execute_input":"2022-06-13T13:21:11.462646Z","iopub.status.idle":"2022-06-13T13:21:11.494465Z","shell.execute_reply.started":"2022-06-13T13:21:11.462558Z","shell.execute_reply":"2022-06-13T13:21:11.493612Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 1) Importing Packages & Import Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Plot\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nplt.rc(\"font\", size=12)\nimport warnings\nwarnings.simplefilter(action='ignore')\n\n# Model\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score  , f1_score\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:11.496384Z","iopub.execute_input":"2022-06-13T13:21:11.497109Z","iopub.status.idle":"2022-06-13T13:21:13.838918Z","shell.execute_reply.started":"2022-06-13T13:21:11.497066Z","shell.execute_reply":"2022-06-13T13:21:13.838103Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Your work\n# Must have\n# 1. Cleansing data\n# 2. Exploratory Data Analysis (describe insight and visualization)\n# 3. Training data - Crossvalidation\n# 4. Testing data","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:13.840068Z","iopub.execute_input":"2022-06-13T13:21:13.840824Z","iopub.status.idle":"2022-06-13T13:21:13.844474Z","shell.execute_reply.started":"2022-06-13T13:21:13.840793Z","shell.execute_reply":"2022-06-13T13:21:13.843809Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Test set","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/dads6003-in-class-competition/test.csv')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:13.846072Z","iopub.execute_input":"2022-06-13T13:21:13.846574Z","iopub.status.idle":"2022-06-13T13:21:13.913795Z","shell.execute_reply.started":"2022-06-13T13:21:13.846541Z","shell.execute_reply":"2022-06-13T13:21:13.913216Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:13.914980Z","iopub.execute_input":"2022-06-13T13:21:13.915364Z","iopub.status.idle":"2022-06-13T13:21:13.937595Z","shell.execute_reply.started":"2022-06-13T13:21:13.915335Z","shell.execute_reply":"2022-06-13T13:21:13.936689Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Training set","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/dads6003-in-class-competition/train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:13.938653Z","iopub.execute_input":"2022-06-13T13:21:13.938878Z","iopub.status.idle":"2022-06-13T13:21:14.024638Z","shell.execute_reply.started":"2022-06-13T13:21:13.938852Z","shell.execute_reply":"2022-06-13T13:21:14.023846Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:14.025797Z","iopub.execute_input":"2022-06-13T13:21:14.026035Z","iopub.status.idle":"2022-06-13T13:21:14.039580Z","shell.execute_reply.started":"2022-06-13T13:21:14.026008Z","shell.execute_reply":"2022-06-13T13:21:14.038778Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Data Quality & Missing Value","metadata":{}},{"cell_type":"code","source":"# describe table\ndf_train.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:14.040772Z","iopub.execute_input":"2022-06-13T13:21:14.041114Z","iopub.status.idle":"2022-06-13T13:21:14.108138Z","shell.execute_reply.started":"2022-06-13T13:21:14.041081Z","shell.execute_reply":"2022-06-13T13:21:14.107292Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:14.110685Z","iopub.execute_input":"2022-06-13T13:21:14.110939Z","iopub.status.idle":"2022-06-13T13:21:14.120359Z","shell.execute_reply.started":"2022-06-13T13:21:14.110911Z","shell.execute_reply":"2022-06-13T13:21:14.119419Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"There are missing values less than 2% (except 'X9'), which median that imputing information","metadata":{}},{"cell_type":"markdown","source":"### Impute Missing Values which Median","metadata":{}},{"cell_type":"code","source":"df_train2 = df_train.copy()\ndf_train2[\"x1\"].fillna(df_train2[\"x1\"].median(skipna=True), inplace=True)\ndf_train2[\"x2\"].fillna(df_train2[\"x2\"].median(skipna=True), inplace=True)\ndf_train2[\"x3\"].fillna(df_train2[\"x3\"].median(skipna=True), inplace=True)\ndf_train2[\"x4\"].fillna(df_train2[\"x4\"].median(skipna=True), inplace=True)\ndf_train2[\"x5\"].fillna(df_train2[\"x5\"].median(skipna=True), inplace=True)\ndf_train2[\"x6\"].fillna(df_train2[\"x6\"].median(skipna=True), inplace=True)\ndf_train2[\"x7\"].fillna(df_train2[\"x7\"].median(skipna=True), inplace=True)\ndf_train2[\"x8\"].fillna(df_train2[\"x8\"].median(skipna=True), inplace=True)\ndf_train2[\"x10\"].fillna(df_train2[\"x10\"].median(skipna=True), inplace=True)\ndf_train2[\"x11\"].fillna(df_train2[\"x11\"].median(skipna=True), inplace=True)\ndf_train2[\"x12\"].fillna(df_train2[\"x12\"].median(skipna=True), inplace=True)\ndf_train2[\"x13\"].fillna(df_train2[\"x13\"].median(skipna=True), inplace=True)\ndf_train2[\"x14\"].fillna(df_train2[\"x14\"].median(skipna=True), inplace=True)\ndf_train2[\"x15\"].fillna(df_train2[\"x15\"].median(skipna=True), inplace=True)\ndf_train2[\"x16\"].fillna(df_train2[\"x16\"].median(skipna=True), inplace=True)\ndf_train2[\"x17\"].fillna(df_train2[\"x17\"].median(skipna=True), inplace=True)\ndf_train2[\"x18\"].fillna(df_train2[\"x18\"].median(skipna=True), inplace=True)\ndf_train2[\"x19\"].fillna(df_train2[\"x19\"].median(skipna=True), inplace=True)\ndf_train2[\"x20\"].fillna(df_train2[\"x20\"].median(skipna=True), inplace=True)\n\ndf_train2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:14.121742Z","iopub.execute_input":"2022-06-13T13:21:14.122230Z","iopub.status.idle":"2022-06-13T13:21:14.173187Z","shell.execute_reply.started":"2022-06-13T13:21:14.122188Z","shell.execute_reply":"2022-06-13T13:21:14.172379Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# re-check missing value \ndf_train2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:14.174449Z","iopub.execute_input":"2022-06-13T13:21:14.175225Z","iopub.status.idle":"2022-06-13T13:21:14.185082Z","shell.execute_reply.started":"2022-06-13T13:21:14.175180Z","shell.execute_reply":"2022-06-13T13:21:14.184112Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 2) Explore data","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=5 , figsize=(20,5) )\nax1 = df_train2[\"x1\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,0]).set_title('X1',fontweight=\"bold\", size=12) # Title\nax2 = df_train2[\"x2\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,1]).set_title('X2',fontweight=\"bold\", size=12) \nax3 = df_train2[\"x3\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,2]).set_title('X3',fontweight=\"bold\", size=12) \nax4 = df_train2[\"x4\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,3]).set_title('X4',fontweight=\"bold\", size=12) \nax5 = df_train2[\"x5\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,4]).set_title('X5',fontweight=\"bold\", size=12) \nax6 = df_train2[\"x6\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,0]).set_title('X6',fontweight=\"bold\", size=12) \nax7 = df_train2[\"x7\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,1]).set_title('X7',fontweight=\"bold\", size=12) \nax8 = df_train2[\"x8\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,2]).set_title('X8',fontweight=\"bold\", size=12) \nax9 = df_train2[\"x9\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,3]).set_title('X9',fontweight=\"bold\", size=12) \nax10 = df_train2[\"x10\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,4]).set_title('X10',fontweight=\"bold\", size=12) ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:14.186489Z","iopub.execute_input":"2022-06-13T13:21:14.186956Z","iopub.status.idle":"2022-06-13T13:21:15.775973Z","shell.execute_reply.started":"2022-06-13T13:21:14.186913Z","shell.execute_reply":"2022-06-13T13:21:15.775178Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=5 , figsize=(20,5) )\nax11  = df_train2[\"x11\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,0]).set_title('x11',fontweight=\"bold\", size=12) # Title\nax12 = df_train2[\"x12\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,1]).set_title('x12',fontweight=\"bold\", size=12) \nax13 = df_train2[\"x13\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,2]).set_title('x13',fontweight=\"bold\", size=12) \nax14 = df_train2[\"x14\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,3]).set_title('x14',fontweight=\"bold\", size=12) \nax15 = df_train2[\"x15\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[0,4]).set_title('x15',fontweight=\"bold\", size=12) \nax16 = df_train2[\"x16\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,0]).set_title('x16',fontweight=\"bold\", size=12) \nax17 = df_train2[\"x17\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,1]).set_title('x17',fontweight=\"bold\", size=12) \nax18 = df_train2[\"x18\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,2]).set_title('x18',fontweight=\"bold\", size=12) \nax19 = df_train2[\"x19\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,3]).set_title('x19',fontweight=\"bold\", size=12) \nax20 = df_train2[\"x20\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6 ,ax=axes[1,4]).set_title('x20',fontweight=\"bold\", size=12) ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:15.777151Z","iopub.execute_input":"2022-06-13T13:21:15.777367Z","iopub.status.idle":"2022-06-13T13:21:17.211648Z","shell.execute_reply.started":"2022-06-13T13:21:15.777341Z","shell.execute_reply":"2022-06-13T13:21:17.210666Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Data X1-X20 are Normal Distribution","metadata":{}},{"cell_type":"markdown","source":"### Correlation","metadata":{}},{"cell_type":"code","source":"corr = df_train2.corr(method ='pearson')\ncorr.style.background_gradient(cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:17.212906Z","iopub.execute_input":"2022-06-13T13:21:17.213212Z","iopub.status.idle":"2022-06-13T13:21:17.354194Z","shell.execute_reply.started":"2022-06-13T13:21:17.213180Z","shell.execute_reply":"2022-06-13T13:21:17.353394Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"x2, x3 , x9 and x15 have inverse correlation with y variable.","metadata":{}},{"cell_type":"code","source":"print(df_train2['y'].value_counts())\nsns.countplot(x='y', data=df_train2, palette='Set3')\n\nplt.title('Number of \"y\" label', fontsize = 14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:17.355229Z","iopub.execute_input":"2022-06-13T13:21:17.355437Z","iopub.status.idle":"2022-06-13T13:21:17.467182Z","shell.execute_reply.started":"2022-06-13T13:21:17.355413Z","shell.execute_reply":"2022-06-13T13:21:17.466631Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## 3) Model\n#### 3.1) Split Data into separate training and validate set","metadata":{}},{"cell_type":"code","source":"# Split data for train model(training/validated set) before submit test dataset.\nX = df_train2.iloc[:,:-1]\ny = df_train2['y']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2 , shuffle=True)\nprint(\"X_train :\", X_train.shape, \"y_train :\", y_train.shape , \"X_val :\" , X_val.shape , \"y_val :\", y_val.shape)\npd.Series(y_train).value_counts()\n\n\nprint('\\nPercent of \"y\" = 0 records is %.2f%%' %((y_train[y_train.iloc[:] == 0].count()/y_train.shape[0])*100))\nprint('Percent of \"y\" = 1 records is %.2f%%' %((y_train[y_train.iloc[:] == 1].count()/y_train.shape[0])*100))\n\nprint('\\nImbalanced data between \"0\" and \"1\" ')\nprint('If the data set in imbalanced , you get a pretty high accuracy just by predicting the majority class(larger portion) , but you fail to capture the minority class (smaller portion) ')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:17.468446Z","iopub.execute_input":"2022-06-13T13:21:17.469253Z","iopub.status.idle":"2022-06-13T13:21:17.487329Z","shell.execute_reply.started":"2022-06-13T13:21:17.469209Z","shell.execute_reply":"2022-06-13T13:21:17.486647Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2) Handle imbalanced dataset which Over-sampling data\n\nOver-sampling is to duplicate records from the minority class","metadata":{}},{"cell_type":"code","source":"# X_train = y_train\npd_train = pd.concat([X_train , y_train] ,axis=1)\n\npos_class = pd_train.loc[pd_train['y'] == 1 ]\nneg_class = pd_train.loc[pd_train['y'] == 0 ]\n\n# over sampling\npd_pos_oversamp = pd.concat([pos_class , pos_class , pos_class] ,axis=0)\npd_train_bal    = pd.concat([neg_class , pd_pos_oversamp] ,axis=0)\n\nprint('Original data:\\n',pd_train.y.value_counts())\nprint('\\nOver sampling which minority class (y=1) 3 times :\\n',pd_train_bal.y.value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:17.488702Z","iopub.execute_input":"2022-06-13T13:21:17.489647Z","iopub.status.idle":"2022-06-13T13:21:17.661461Z","shell.execute_reply.started":"2022-06-13T13:21:17.489601Z","shell.execute_reply":"2022-06-13T13:21:17.660626Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"Y_train_2 = pd_train_bal['y']\nX_train_2 = pd_train_bal.drop( ['y'] , axis=1)\n\nprint('New dataset for training model.')\nprint('X_train_2 :', X_train_2.x1.count())\nprint('Y_train_2 :', Y_train_2.count())","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:17.662815Z","iopub.execute_input":"2022-06-13T13:21:17.663094Z","iopub.status.idle":"2022-06-13T13:21:17.672913Z","shell.execute_reply.started":"2022-06-13T13:21:17.663053Z","shell.execute_reply":"2022-06-13T13:21:17.671916Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3) XGBoost Model and Results","metadata":{}},{"cell_type":"code","source":"# XGBClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\n#initial modal\nmodel_XGB = xgb.XGBClassifier(n_estimators=100, max_depth=10 , eval_metric='logloss' , seed = 20)\nmodel_XGB.fit(X_train_2, Y_train_2)\ny_pred = model_XGB.predict(X_val)\n\n# Accuracy\nprint('train accuracy XGB all features :' , round(model_XGB.score(X_train_2, Y_train_2)*100, 2))\nprint('valid accuracy XGB all features :' , round(accuracy_score(y_val, y_pred)*100, 2))\nprint('F-1 score XGB all features:'    , round(f1_score(y_val, y_pred)*100, 2))\n\nprint('\\n', classification_report(y_val, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:17.674138Z","iopub.execute_input":"2022-06-13T13:21:17.674403Z","iopub.status.idle":"2022-06-13T13:21:19.763854Z","shell.execute_reply.started":"2022-06-13T13:21:17.674370Z","shell.execute_reply":"2022-06-13T13:21:19.763197Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# K-fold \nkfold = model_selection.KFold(n_splits=5, random_state=7, shuffle=True)\n\nresults_acc_XGB = model_selection.cross_val_score(model_XGB, X_train_2, Y_train_2, cv=kfold, scoring=\"accuracy\")\nresults_f1_XGB  = model_selection.cross_val_score(model_XGB, X_train_2, Y_train_2, cv=kfold, scoring = \"f1\")\n\nprint(\"\\nK-fold cross validation average accuracy: %.2f%%\" % (results_acc_XGB.mean()*100))\nprint(\"K-fold cross validation average F-1: %.2f%%\" % (results_f1_XGB.mean()*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:19.765044Z","iopub.execute_input":"2022-06-13T13:21:19.766107Z","iopub.status.idle":"2022-06-13T13:21:35.680051Z","shell.execute_reply.started":"2022-06-13T13:21:19.766074Z","shell.execute_reply":"2022-06-13T13:21:35.678358Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## 4) Tuning Model\n#### 4.1) Hyperparameter tuning which Grid Search \nA Grid Search is an exhaustive search over every combination of specified parameter values.","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# params = { 'max_depth': [3,6,10,15],\n#            'learning_rate': [0.01, 0.05, 0.1, 0.3], #0.5\n#            'n_estimators': [100, 500, 1000],\n#            'colsample_bytree': [0.3, 0.7 ,1.0],\n#           }\n\n \n# xgbr = xgb.XGBClassifier(eval_metric='logloss' , seed = 20)\n\n# clf = GridSearchCV(estimator=xgbr, \n#                    param_grid=params,\n#                    scoring='neg_mean_squared_error', \n#                    verbose=1)\n\n# clf.fit(X_train_2, Y_train_2)\n# print(\"Best parameters:\", clf.best_params_)\n# print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:35.683491Z","iopub.execute_input":"2022-06-13T13:21:35.683879Z","iopub.status.idle":"2022-06-13T13:21:35.690816Z","shell.execute_reply.started":"2022-06-13T13:21:35.683840Z","shell.execute_reply":"2022-06-13T13:21:35.690216Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Fitting 5 folds for each of 144 candidates, totalling 720 fits\nBest parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 1000}\n\nLowest RMSE:  0.09047563599093737","metadata":{}},{"cell_type":"code","source":"# Use best parameters\nmodel_XGB_cv = xgb.XGBClassifier( n_estimators = 1000 , max_depth = 3 , learning_rate=0.1 , colsample_bytree= 0.7 , seed = 20 , eval_metric='logloss')\n\nmodel_XGB_cv.fit(X_train_2, Y_train_2)\ny_pred_CV = model_XGB_cv.predict(X_val)\n\n# Accuracy\nprint('train_acc XGB CV ' , round(model_XGB_cv.score(X_train_2, Y_train_2)*100, 2))\nprint('valid_acc XGB CV' , round(accuracy_score(y_val, y_pred_CV)*100, 2))\nprint('f1_scr XGB CV' , round(f1_score(y_val, y_pred_CV)*100, 2))\n\n# K-fold \nkfold = model_selection.KFold(n_splits=5, random_state=7, shuffle=True)\n\nacc_XGB = model_selection.cross_val_score(model_XGB_cv, X_train_2, Y_train_2, cv=kfold, scoring=\"accuracy\")\nf1_XGB  = model_selection.cross_val_score(model_XGB_cv, X_train_2, Y_train_2, cv=kfold, scoring = \"f1\")\nprint(\"K-fold cross validation average accuracy: %.2f%%\" % (acc_XGB.mean()*100))\nprint(\"K-fold cross validation average F-1: %.2f%%\" % (f1_XGB.mean()*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:21:35.692118Z","iopub.execute_input":"2022-06-13T13:21:35.692884Z","iopub.status.idle":"2022-06-13T13:23:01.320308Z","shell.execute_reply.started":"2022-06-13T13:21:35.692840Z","shell.execute_reply":"2022-06-13T13:23:01.319674Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#### 4.1) Feature selection : Recursive feature elimination (RFE)","metadata":{}},{"cell_type":"code","source":"# Recursive feature elimination (RFE)\nfrom sklearn.feature_selection import RFE\n\nn_features_to_select = 1\nrfe = RFE(model_XGB_cv , n_features_to_select=n_features_to_select )\nrfe.fit(X_train_2, Y_train_2)\n\nfrom operator import itemgetter\nfeatures = X_train_2.columns.to_list()\nfor x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n    print(x, y)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:23:01.321402Z","iopub.execute_input":"2022-06-13T13:23:01.321813Z","iopub.status.idle":"2022-06-13T13:25:27.192106Z","shell.execute_reply.started":"2022-06-13T13:23:01.321776Z","shell.execute_reply":"2022-06-13T13:25:27.191391Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2) Feature Importance","metadata":{}},{"cell_type":"code","source":"# Feature Importance\nfeature_importance = model_XGB_cv.feature_importances_\nsorted_idx = np.argsort(feature_importance)\nfig = plt.figure(figsize=(12, 6))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), np.array(X_val.columns)[sorted_idx])\nplt.title('Feature Importance')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:25:27.195104Z","iopub.execute_input":"2022-06-13T13:25:27.195318Z","iopub.status.idle":"2022-06-13T13:25:27.438592Z","shell.execute_reply.started":"2022-06-13T13:25:27.195292Z","shell.execute_reply":"2022-06-13T13:25:27.437666Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Choose the top 10 featues and use them for the model\nn_features_to_select = 10\n\n# CV_rfe = RFE( clf.best_estimator_.fit(X_train_2, Y_train_2) , n_features_to_select=n_features_to_select )\nCV_rfe_sel = RFE(model_XGB_cv , n_features_to_select=n_features_to_select )\nCV_rfe_sel.fit(X_train_2, Y_train_2)\nrfe_y_pred = CV_rfe_sel.predict(X_val)\n\n# Accuracy\nprint('train accuracy XGB CV with 10 features' , round(CV_rfe_sel.score(X_train_2, Y_train_2)*100, 2))\nprint('valid accuracy XGB CV with 10 features' , round(accuracy_score(y_val, rfe_y_pred)*100, 2))\nprint('F-1 score XGB CV with 10 features' , round(f1_score(y_val, rfe_y_pred)*100, 2))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:25:27.440109Z","iopub.execute_input":"2022-06-13T13:25:27.440358Z","iopub.status.idle":"2022-06-13T13:27:00.306010Z","shell.execute_reply.started":"2022-06-13T13:25:27.440327Z","shell.execute_reply":"2022-06-13T13:27:00.305297Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## 5) Make Predictions on Test Set and Output\nFinally, choose model after tuning hypermarameter which Grid search and selected 10 features to predict the test dataset because that's the best accuracy and F-1 in the validated dataset.","metadata":{}},{"cell_type":"code","source":"n_features_to_select = 10\n\nrfe = RFE(model_XGB_cv, n_features_to_select=n_features_to_select )\nrfe.fit(X_train_2, Y_train_2)\ny_pred = rfe.predict(X_val)\n\n# Accuracy\nprint('Train accuracy' , round(rfe.score(X_train_2, Y_train_2)*100, 2))\nprint('Valid accuracy' , round(accuracy_score(y_val, y_pred)*100, 2))\nprint('F-1 score' , round(f1_score(y_val, y_pred)*100, 2))\n\nprint('\\n', classification_report(y_val, y_pred))\n\n# confusion matrix\nmatrix_ = confusion_matrix(y_val,y_pred, labels=[1,0])\nsns.heatmap(matrix_, annot=True, cmap='Blues',fmt='d', cbar=False).set(title='Confusion Matrix : XGBoost')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:27:00.309482Z","iopub.execute_input":"2022-06-13T13:27:00.309869Z","iopub.status.idle":"2022-06-13T13:28:33.740589Z","shell.execute_reply.started":"2022-06-13T13:27:00.309833Z","shell.execute_reply":"2022-06-13T13:28:33.739598Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"**Output for submission**","metadata":{}},{"cell_type":"code","source":"# Prediction : choose best accuracy in validated dataset\ny_pred = rfe.predict(df_test)\n\n# Export\nfields = ['id','Expected']\nid = list(range(1,2501))\ndf_test['Id']=pd.Series(id)\ndf_test['Expected']=pd.Series(y_pred)\nfinal_test = df_test[['Id','Expected']]\n\n# export\nfinal_test.to_csv('submit.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T13:28:33.742477Z","iopub.execute_input":"2022-06-13T13:28:33.743622Z","iopub.status.idle":"2022-06-13T13:28:33.780011Z","shell.execute_reply.started":"2022-06-13T13:28:33.743568Z","shell.execute_reply":"2022-06-13T13:28:33.779260Z"},"trusted":true},"execution_count":27,"outputs":[]}]}